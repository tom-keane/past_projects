---
title: "Thesis"
author: "Thomas Keane"
date: "7 January 2019"
output:
  word_document: default
  pdf_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=T, results='hide'}
```


Similarity, Adjacency, and Laplacian Functions
```{r}
## Gaussian Similarity Function
gaussiandist <- function(data, sigmasq = 1, ...){
  
  # Calculate gaussian distance using formula
  distances <- exp(-(1/(2 * sigmasq)) *(as.matrix(dist(data,method = "euclidean"),nrow = nrow(data))^2))
  
  # Set diagonal equal to zero
  diag(distances) <- 0
  
  #return matrix
  distances
  }

## Local Scale Similarity Function
localscale <- function(data, Kscale, ...){
  
  # Initialise row count, and euclidean matrix
  N <- nrow(data)
  Matrix <- matrix(rep(0,N^2),ncol = N)
  euclid <- as.matrix(dist(data,method = "euclidean"), nrow = N)
  for(i in 1:N){
    
    # Order neighbours based on euclidean distance and set Kth neighbour
    kneighbour <- as.vector(order(euclid[i,]))
    kneighbour <- kneighbour[(unlist(Kscale)+1)]
    for(j in 1:i){
      
      # Calculate similarity using local scale formula and generate matrix
      d <- as.numeric(exp(-(euclid[i,j])^2/(euclid[i,kneighbour]*euclid[j,kneighbour])))
      Matrix[i,j] <- d
      Matrix[j,i] <- d
    }
  }
  
  # Set diagonal equal to 0
  diag(Matrix) <- 0
  
  # Return Matrix
  Matrix
}

## Correlation Similarity Function
Correlation <- function(data, ...){
  S <- cor(t(data))+1
  diag(S) = 0
  S[is.na(S)] = 0
  S
}


## Blank adjacency function
blankadjacency <- function(similaritymatrix,...){
  similaritymatrix
}


## Epsilon - neighbourhood adjacency function
epneighbour <- function(similaritymatrix, epsilon,...){
  N <- nrow(similaritymatrix)
  Adjacencymatrix <- matrix(rep(0,N^2),nrow = N, ncol = N)
  for(i in 1:N){
    j <- which(similaritymatrix[i,] >= epsilon)
    Adjacencymatrix[i,j] <- 1
    Adjacencymatrix[j,i] <- 1}
  Adjacencymatrix
}

## k-NN adjacency function
kNN <- function(similaritymatrix, k, weighted = TRUE,...){
  N <- nrow(similaritymatrix)
  Adjacencymatrix <- matrix(rep(0,N^2), nrow = N, ncol = N)
  for(i in 1:N){
  kneighbour <- sort(similaritymatrix[i,], decreasing = T)[1:k]
  for (n in kneighbour){
    j <- which(similaritymatrix[i,] == n)
    if(weighted==TRUE){
      Adjacencymatrix[i,j] <- similaritymatrix[i,j]
      Adjacencymatrix[j,i] <- similaritymatrix[i,j]}
    else{
      Adjacencymatrix[i,j] <- 1
      Adjacencymatrix[j,i] <- 1
    }
  }} 
  Adjacencymatrix
}


## Unnormalised Laplacian
laplace_unnorm <- function(A){
  D <- diag(rowSums(A))
  Laplacian <- D - A
}

## Laplacian according to Ng-Jordan-Weiss
laplace_NJW <- function(A){
  D <- 1/sqrt(rowSums(A))
  Laplacian <- D* A %*% diag(D)
}

## Normalised Laplacian
laplace_norm <- function(A){
  D <- 1/sqrt(rowSums(A))
  L <- diag(rowSums(A)) - A
  Laplacian <- D* L %*% diag(D)
}
```


Clustering Functions
```{r}
## Laplacian eigenvalue function 
laplacian.eigenvalues <- function(A,laplace){
  Laplacian <- laplace(A)
  eigen <- eigen(Laplacian,symmetric = T)
  eigen
}

## Clustering Function
Clustering <- function(A, laplace, laplace_name, centers){
  
  # Calculate eigen values and vectors
  # Note: eigen function provides normalised vectors
  eigen <- laplacian.eigenvalues(A, laplace)
  
  # Identify type of Laplacian used
  if(laplace_name =="laplace_NJW"){
     # Take eigenvectors corresponding to k largest eigen values
    values <- eigen$values
    vectors <- eigen$vectors[,1:centers]
  } else{
    n <- nrow(A)
    # Take eigenvectors corresponding to k smallest eigen values
    values <- eigen$values
    vectors <- eigen$vectors[,(n+1-centers):n]
  }
  # Kmeans on eigenvectors and return clustering
  kmeans <- kmeans(vectors, centers = centers, nstart = 200)
  return(list(Clustering = kmeans,EigenValues = values,EigenVectors = vectors))
}

## Spectral Clustering Function
Spec.Cluster <- function(data, similarity, adjacency, laplace, centers, ...){
  
  # Laplacian type passed due to reversing of eigenvector order depending on laplacian type
  laplace_name = deparse(substitute(laplace))
  
  # Retrieving required variables for similarity construction
  Snames <- names(formals(similarity))
  # Retrieving required variables for adjacency construction
  Anames <- names(formals(adjacency))
  
  # Converting ellipsis into list
  dots <- list(...)
  
  # Splitting arguments into separate lists for similarity and adjacency
  Sarg <- dots[names(dots) %in% Snames]
  Aarg <- dots[names(dots) %in% Anames]
  if(length(Sarg)==0){Sarg = NULL}
  if(length(Aarg)==0){Aarg = NULL}
  
  # Creating Similarity and Adjacency matrices
  S <- similarity(data,Sarg, ...)
  A <- adjacency(S, Aarg, ...)
  
  # Clustering and returning k - means clustering object
  Clustering(A,laplace, laplace_name, centers)
}
```


```{r}
# Load in Path based data
pathbaseddata <- read.csv("C:\\Users\\Tom\\Dropbox\\University\\Fourth Year\\Semester 1\\Research\\pathbased.csv",header = FALSE)

# Load in Spirals data
spiralsdata <- read.csv("C:\\Users\\Tom\\Dropbox\\University\\Fourth Year\\Semester 1\\Research\\spirals.csv",header = FALSE)

# Split data sets into test data 1,2, and 3
testdata1 <- spiralsdata[,1:2]
testdata2 <- pathbaseddata[,1:2]
testdata3 <- iris[,1:4]

# split Cluster membership into vectors
testmembership1 <- spiralsdata[,3]
testmembership2 <- pathbaseddata[,3]
testmembership3 <- iris[,5]
levels(testmembership3) <- c(1,2,3)
testmembership3 <- as.numeric(testmembership3)
```

```{r}
# Plot Spirals data and save
filename <- paste("Thesis examples/","SpiralsTrueClusters",".png", sep="")
png(filename = filename, width = 530, height = 480, units = "px")
par(xpd = T, mar = par()$mar + c(0,0,0,5))
plot(testdata1[,1] ,testdata1[,2] , col = testmembership1, xlab = "x", ylab = "y")
legend(35,20, legend=c("Cluster A","Cluster B","Cluster C"),col=c("red","green","black"),pch=1,xpd=NA)
dev.off()

# Plot Pathbased data and save
filename <- paste("Thesis examples/","PathbasedTrueClusters",".png", sep="")
png(filename = filename, width = 530, height = 480, units = "px")
par(xpd = T, mar = par()$mar + c(0,0,0,5))
plot(testdata2[,1] ,testdata2[,2] , col = testmembership2,  xlab = "x", ylab = "y")
legend(35,20, legend=c("Cluster A","Cluster B","Cluster C"),col=c("red","green","black"),pch=1,xpd=NA)
dev.off()

# Plot Iris data and save
filename <- paste("Thesis examples/","IrisTrueClusters",".png", sep="")
png(filename = filename, width = 530, height = 480, units = "px")
pairs(testdata3, col = c("red","green","black")[unclass(iris$Species)], oma=c(3,3,3,13))
legend("right", legend=levels(iris$Species), col=c("red","green","black"),pch=1,xpd=NA)
dev.off()

```

```{r}
# Loop over 4 values for sigma squared: .5, 1, 1.5, 2
for(sigmasq in 1:4*.5){
  
# Create cluster object for given sigmasq
clusterobject <- Spec.Cluster(data = testdata1, similarity = gaussiandist, adjacency = blankadjacency, centers = 3, laplace = laplace_unnorm, sigmasq = sigmasq)
# Set variable equal to cluster membership
gaussianspirals <- clusterobject$Clustering$cluster

# Generate Plot of clustering and save
filename <- paste("Thesis examples/","Spiralsplot", toString(sigmasq),".png", sep="")
png(filename = filename, width = 530, height = 480, units = "px")
par(xpd = T, mar = par()$mar + c(0,0,0,5))
plot(testdata1[,1] ,testdata1[,2] , col = gaussianspirals, xlab = "x", ylab = "y")
legend(35,20, legend=c("Cluster 1","Cluster 2","Cluster 3"),col=c("red","green","black"),pch=1,xpd=NA)
dev.off()


# Generate Plot of eigenvectors and save
filename <- paste("Thesis examples/","SpiralsEV", toString(sigmasq),".png", sep="")
png(filename = filename, width = 530, height = 480, units = "px")
pairs(clusterobject$EigenVectors, col = gaussianspirals, oma=c(3,3,3,13))
legend("right", legend=c("Cluster 1","Cluster 2","Cluster 3"),col=c("red","green","black"),pch=1,xpd=NA)
dev.off()
}
```



```{r}
# Generate matrix to hold sum of squares
sumofsquares <- matrix(rep(0,4),nrow = 1)

# Loop over 4 values of sigma
for(sigmasq in 1:4*.5){

# Generate total within sum of squares and store in matrix
sumofsquares[(sigmasq/.5)] <- Spec.Cluster(data = testdata1, similarity = gaussiandist, adjacency = blankadjacency, centers = 3, laplace = laplace_unnorm, sigmasq = sigmasq)$Clustering$tot.withinss}

# Find minimum sum of squares and transform back into sigma value
bestSigmasq <- which(sumofsquares == min(sumofsquares), arr.ind = TRUE)[2]*.5
```


```{r}
library("mclust")

# Create Variables to store optimal parameters
bestRI <- 0
bestKscale <- 0
bestk <- 0

# Grid search using nested loops
for(Kscale in  3:15){
  for(k in (10:30)*5){
    
# Clustering using current parmeters
localscalepathbased <- Spec.Cluster(data = testdata2, similarity = localscale, adjacency = kNN, centers = 3, laplace = laplace_norm, Kscale = Kscale, k = k, weighted = FALSE)$Clustering$cluster


# Compute adjusted rand index of current clustering
RI <- adjustedRandIndex(localscalepathbased, testmembership2)

# Compare adjusted rand index to current best and replace parameters if better
if(bestRI <RI){
  bestk <- k
  bestKscale <- Kscale
  bestRI <- RI
}}}

# Best clustering occurs at 10,110
# Create cluster object with optimal parameters
clusterobject <- Spec.Cluster(data = testdata2, similarity = localscale, adjacency = kNN, centers = 3, laplace = laplace_norm, Kscale = bestKscale, k = bestk, weighted = FALSE)
localscalepathbased <- clusterobject$Clustering$cluster

# Plot optimal clustering
filename <- paste("Thesis examples/","PathBasedplot", toString(bestk),",",toString(bestKscale),".png", sep="")
png(filename = filename, width = 530, height = 480, units = "px")
par(xpd = T, mar = par()$mar + c(0,0,0,5))
plot(testdata2[,1] ,testdata2[,2] , col = localscalepathbased, xlab = "x", ylab = "y")
legend(35,20, legend=c("Cluster 1","Cluster 2","Cluster 3"),col=c("red","green","black"),pch=1,xpd=NA)
dev.off()

# Output confusion matrix of results
table(localscalepathbased, testmembership2)
```


```{r}
# Plot eigenvectors of optimal clustering and save
filename <- paste("Thesis examples/","PathbasedEV", toString(bestk),",",toString(bestKscale),".png", sep="")
png(filename = filename, width = 530, height = 480, units = "px")
pairs(clusterobject$EigenVectors, col = localscalepathbased, oma=c(3,3,3,13))
legend("right", legend=c("Cluster 1","Cluster 2","Cluster 3"),col=c("red","green","black"),pch=1,xpd=NA)
dev.off()
```




```{r}
# Generate matrix to hold sum of squares
sumofsquares <- matrix(rep(0,13*21),nrow = 13,ncol = 21)

# Grid search using nested loops
for(Kscale in  3:15){
  for(k in (1:20)*5){
    
# Calculate and store sum of squares of each iteration
sumofsquares[Kscale-2,(k/5)] <- Spec.Cluster(data = testdata3, similarity = localscale, adjacency = kNN, centers = 3, laplace = laplace_norm, Kscale = Kscale, k =k)$Clustering$tot.withinss
  }}

# Find minimum sum of squares and transform back to parameters
bestKscale <- which(sumofsquares == min(sumofsquares), arr.ind = TRUE)[1]+2
bestk <- (which(sumofsquares == min(sumofsquares), arr.ind = TRUE)[2])*5

# Optimal parmeters of 3 , 10
# Create cluster object using the optimal parameters
clusterobject <- Spec.Cluster(data = testdata2, similarity = localscale, adjacency = kNN, centers = 3, laplace = laplace_norm, Kscale = bestKscale, k = bestk, weighted = FALSE)
localscalepathbased <- clusterobject$Clustering$cluster

# Plot optimal cluster results and save
filename <- paste("Thesis examples/","PathBasedplot", toString(bestk),",",toString(bestKscale),".png", sep="")
png(filename = filename, width = 530, height = 480, units = "px")
par(xpd = T, mar = par()$mar + c(0,0,0,5))
plot(testdata2[,1] ,testdata2[,2] , col = localscalepathbased, xlab = "x", ylab = "y")
legend(35,20, legend=c("Cluster 1","Cluster 2","Cluster 3"),col=c("red","green","black"),pch=1,xpd=NA)
dev.off()

# Output confusion matrix of optimal cluster results
table(localscalepathbased, testmembership2)
```

```{r}
# Generate plot of eigenvectors used in clustering and save
filename <- paste("Thesis examples/","PathbasedEV", toString(bestk),",",toString(bestKscale),".png", sep="")
png(filename = filename, width = 530, height = 480, units = "px")
pairs(clusterobject$EigenVectors, col = localscalepathbased, oma=c(3,3,3,13))
legend("right", legend=c("Cluster 1","Cluster 2","Cluster 3"),col=c("red","green","black"),pch=1,xpd=NA)
dev.off()
```


```{r}
# Create Variables to store optimal parameters
bestRI <- 0
bestKscale <- 0
bestk <- 0

# Grid search using nested loops
for(Kscale in  3:15){
  for(k in (5:20)){
    
# Clustering using current parmeters
localscaleiris <- Spec.Cluster(data = testdata3, similarity = localscale, adjacency = kNN, centers = 3, laplace = laplace_NJW, Kscale = Kscale, k = k)$Clustering$cluster


# Compute adjusted rand index of current clustering
RI <- adjustedRandIndex(localscaleiris, testmembership3)


# Compare adjusted rand index to current best and replace parameters if better
if(bestRI <RI){
  bestk <- k
  bestKscale <- Kscale
  bestRI <- RI
}}}
```




```{r}
# Optimal Parameters 12, 12
# Create cluster object using optimal parameters
clusterobject <- Spec.Cluster(data = testdata3, similarity = localscale, adjacency = kNN, centers = 3, laplace = laplace_NJW, Kscale = bestKscale, k = bestk)
localscaleiris <- clusterobject$Clustering$cluster

# Plot optimal cluster results and save 
filename <- paste("Thesis examples/","Irisdata", toString(bestk),",",toString(bestKscale),".png", sep="")
png(filename = filename, width = 530, height = 480, units = "px")
pairs(testdata3, col = localscaleiris, oma = c(3,3,3,13))
legend("right", legend=c("Cluster 1","Cluster 2","Cluster 3"),col=c("red","green","black"),pch=1,xpd=NA)
dev.off()

# Output confusion matrix of optimal cluster results
print(table(localscaleiris,testmembership3))
```

```{r}

# Plot eigen vectors used for optimal cluster results and save 
filename <- paste("Thesis examples/","IrisdataEV", toString(bestk),",",toString(bestKscale),".png", sep="")
png(filename = filename, width = 530, height = 480, units = "px")
pairs(clusterobject$EigenVectors, col = localscaleiris,  oma = c(3,3,3,13))
legend("right", legend=c("Cluster 1","Cluster 2","Cluster 3"),col=c("red","green","black"),pch=1,xpd=NA)
dev.off()
```




```{r}
# Generate matrix to store sum of squares
sumofsquares <- matrix(rep(0,13*16),nrow = 13,ncol = 16)

# Grid search using nested loops
for(Kscale in  3:15){
  for(k in (5:20)){
    
# Calculate and store sum of squares of each iteration
sumofsquares[Kscale-2,k-4] <- Spec.Cluster(data = testdata3, similarity = localscale, adjacency = kNN, centers = 3, laplace = laplace_NJW, Kscale = Kscale, k =k)$Clustering$tot.withinss}}

# Find minimum sum of squares and transform back to parameters
bestKscale <- which(sumofsquares == min(sumofsquares), arr.ind = TRUE)[1]+2
bestk <- which(sumofsquares == min(sumofsquares), arr.ind = TRUE)[2]+4
```


```{r}
# Optimal Parameters 5,11
# Generate cluster object with optimal parameters
clusterobject <- Spec.Cluster(data = testdata3, similarity = localscale, adjacency = kNN, centers = 3, laplace = laplace_NJW, Kscale = bestKscale, k = bestk)
localscaleiris <- clusterobject$Clustering$cluster

# Plot optimal clusters and save
filename <- paste("Thesis examples/","Irisdata", toString(bestk),",",toString(bestKscale),".png", sep="")
png(filename = filename, width = 530, height = 480, units = "px")
pairs(testdata3, col = localscaleiris,oma = c(3,3,3,13))
legend("right", legend=c("Cluster 1","Cluster 2","Cluster 3"),col=c("red","green","black"),pch=1,xpd=NA)
dev.off()

# Output confusion matrix of optimal clustering
print(table(localscaleiris,testmembership3))
```



```{r}
# Plot eigenvectors used for optimal clustering and save
filename <- paste("Thesis examples/","IrisdataEV", toString(bestk),",",toString(bestKscale),".png", sep="")
png(filename = filename, width = 530, height = 480, units = "px")
pairs(clusterobject$EigenVectors, col = localscaleiris,  oma = c(3,3,3,13))
legend("right", legend=c("Cluster 1","Cluster 2","Cluster 3"),col=c("red","green","black"),pch=1,xpd=NA)
dev.off()
```
